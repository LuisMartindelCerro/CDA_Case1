{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/data_5KNN.csv')\n",
    "y = df.iloc[:, 0]\n",
    "X = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
      "best estimator: BaggingRegressor(estimator=DecisionTreeRegressor(), max_features=0.7,\n",
      "                 n_estimators=162, oob_score=True, random_state=42)\n",
      "Best Estimator: BaggingRegressor(estimator=DecisionTreeRegressor(), max_features=0.7,\n",
      "                 n_estimators=162, oob_score=True, random_state=42)\n",
      "Root Mean Squared Error (RMSE) on Test Set: 53.397535290673254\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingRegressor(DecisionTreeRegressor(), bootstrap=True, oob_score=True, random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators':range(100, 200),  # Number of trees in the ensemble\n",
    "    'max_samples': [0.5, 0.7, 1.0],  # Proportion of training data per tree\n",
    "    'max_features': [0.5, 0.7, 1.0]  # Proportion of features per tree\n",
    "}\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "bagging_grid = GridSearchCV(estimator=bagging, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search model\n",
    "bagging_grid.fit(X, y)\n",
    "\n",
    "# Get best model\n",
    "best_bagging = bagging_grid.best_estimator_\n",
    "\n",
    "# Cross-validation evaluation\n",
    "scores = cross_val_score(best_bagging, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"Mean RMSE for Bagging Regressor: {np.mean(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAYBE THERE SOULD BE PARAMETERS LIKE MINLEAF ON RF TO PREVENT OVERFITTING?\n",
    "\n",
    "rf = RandomForestRegressor(bootstrap=True, oob_score=True,random_state=0)\n",
    "\n",
    "# number of trees\n",
    "n_estimators = range(5,101)\n",
    "max_depth = range(1,11)\n",
    "max_features = range(1,50,5)\n",
    "\n",
    "# Try to add more of the parameters from the model and then add them to this dict to see how it affects the model.\n",
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "rf_grid.fit(X, y)\n",
    "\n",
    "# Get best model\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Cross-validation evaluation\n",
    "scores = cross_val_score(best_rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"Mean RMSE for Random Forest: {np.mean(rmse_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define boosting model\n",
    "boosting = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': range(50, 150),\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "boosting_grid = GridSearchCV(boosting, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "boosting_grid.fit(X, y)\n",
    "\n",
    "# Get best model\n",
    "best_boosting = boosting_grid.best_estimator_\n",
    "\n",
    "# Cross-validation evaluation\n",
    "scores = cross_val_score(best_boosting, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"Mean RMSE for Gradient Boosting: {np.mean(rmse_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
